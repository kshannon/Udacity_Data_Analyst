{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LESSON 3 NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of Data Quality:\n",
    "- **Validity**: Conforms to a schema\n",
    "    - determing what the constraints are on individual fields and checking to ensure the field values conform to those restraints.\n",
    "- **Accuracy**: conforms to a gold standard\n",
    "- **Completness**: All Records??\n",
    "- **Consistency**: Matches other data?\n",
    "- **Uniformity**: Same Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blueprint for Cleaning Data:\n",
    "1. Audit the Data: programatically check data, possibly use statistical means to check for outliers etc. \n",
    "2. Create a data cleaning plan: Use info from audit to:\n",
    "    - Identify Causes\n",
    "    - Define Causes\n",
    "    - Test\n",
    "3. Execute Plan: i.e. run a script to clean the data. \n",
    "4. Manually Correct: If needed.\n",
    "\n",
    "Go back and Audit the data again... Do a few iterations to build confidence in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LESSON 2.a - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Please note that the function 'make_request' is provided for your reference only.\n",
    "# You will not be able to to actually use it from within the Udacity web UI.\n",
    "# Your task is to process the HTML using BeautifulSoup, extract the hidden\n",
    "# form field values for \"__EVENTVALIDATION\" and \"__VIEWSTATE\" and set the appropriate\n",
    "# values in the data dictionary.\n",
    "# All your changes should be in the 'extract_data' function\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "html_page = \"page_source.html\"\n",
    "\n",
    "def extract_data(page):\n",
    "    data = {\"eventvalidation\": \"\",\n",
    "            \"viewstate\": \"\"}\n",
    "    with open(page, \"r\") as html:\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        ev = soup.find(id=\"__EVENTVALIDATION\")\n",
    "        data[\"eventvalidation\"] = ev[\"value\"]\n",
    "\n",
    "        vs = soup.find(id=\"__VIEWSTATE\")\n",
    "        data[\"viewstate\"] = vs[\"value\"]\n",
    "\n",
    "    return data\n",
    "\n",
    "def make_request(data):\n",
    "    eventvalidation = data[\"eventvalidation\"]\n",
    "    viewstate = data[\"viewstate\"]\n",
    "\n",
    "    r = requests.post(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "                    data={'AirportList': \"BOS\",\n",
    "                          'CarrierList': \"VX\",\n",
    "                          'Submit': 'Submit',\n",
    "                          \"__EVENTTARGET\": \"\",\n",
    "                          \"__EVENTARGUMENT\": \"\",\n",
    "                          \"__EVENTVALIDATION\": eventvalidation,\n",
    "                          \"__VIEWSTATE\": viewstate\n",
    "                    })\n",
    "\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = extract_data(html_page)\n",
    "    assert data[\"eventvalidation\"] != \"\"\n",
    "    assert data[\"eventvalidation\"].startswith(\"/wEWjAkCoIj1ng0\")\n",
    "    assert data[\"viewstate\"].startswith(\"/wEPDwUKLTI\")\n",
    "\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LESSON 3 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'22-rdf-syntax-ns#type_label': '{animal|arachnid|eukaryote|species|owl#Thing}', 'family': 'http://dbpedia.org/resource/Orb-weaver_spider', 'conservationStatusSystem': 'NULL', 'family_label': 'Orb-weaver spider', 'depiction': 'http://upload.wikimedia.org/wikipedia/commons/f/fd/Argiope_sp.jpg', 'phylum': 'http://dbpedia.org/resource/Arthropod', 'thumbnail_label': '200px-Argiope_sp.jpg', 'conservationStatus': 'NULL', 'species': 'NULL', 'rdf-schema#label': 'Argiope (spider)', 'order_label': 'Spider', 'binomialAuthority': 'NULL', 'division_label': 'NULL', 'kingdom_label': 'Animal', 'binomialAuthority_label': 'NULL', 'thumbnail': 'http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Argiope_sp.jpg/200px-Argiope_sp.jpg', 'kingdom': 'http://dbpedia.org/resource/Animal', 'division': 'NULL', 'class_label': 'Arachnid', 'phylum_label': 'Arthropod', 'URI': 'http://dbpedia.org/resource/Argiope_(spider)', '22-rdf-syntax-ns#type': '{http://dbpedia.org/ontology/Animal|http://dbpedia.org/ontology/Arachnid|http://dbpedia.org/ontology/Eukaryote|http://dbpedia.org/ontology/Species|http://www.w3.org/2002/07/owl#Thing}', 'species_label': 'NULL', 'rdf-schema#comment': 'The genus Argiope includes rather large and spectacular spiders that often have a strikingly coloured abdomen. These spiders are distributed throughout the world. Most countries in tropical or temperate climates host one or more species that are similar in appearance. The etymology of the name is from a Greek name meaning silver-faced.', 'class': 'http://dbpedia.org/resource/Arachnid', 'depiction_label': 'Argiope_sp.jpg', 'synonym': 'NULL', 'name': 'Argiope', 'genus_label': 'NULL', 'genus': 'NULL', 'order': 'http://dbpedia.org/resource/Spider'}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with another type of infobox data, audit it, clean it, \n",
    "come up with a data model, insert it into a MongoDB and then run some queries against your database.\n",
    "The set contains data about Arachnid class.\n",
    "Your task in this exercise is to parse the file, process only the fields that are listed in the\n",
    "FIELDS dictionary as keys, and return a list of dictionaries of cleaned values. \n",
    "\n",
    "The following things should be done:\n",
    "- keys of the dictionary changed according to the mapping in FIELDS dictionary\n",
    "- trim out redundant description in parenthesis from the 'rdf-schema#label' field, like \"(spider)\"\n",
    "- if 'name' is \"NULL\" or contains non-alphanumeric characters, set it to the same value as 'label'.\n",
    "- if a value of a field is \"NULL\", convert it to None\n",
    "- if there is a value in 'synonym', it should be converted to an array (list)\n",
    "  by stripping the \"{}\" characters and splitting the string on \"|\". Rest of the cleanup is up to you,\n",
    "  eg removing \"*\" prefixes etc. If there is a singular synonym, the value should still be formatted\n",
    "  in a list.\n",
    "- strip leading and ending whitespace from all fields, if there is any\n",
    "- the output structure should be as follows:\n",
    "{ 'label': 'Argiope',\n",
    "  'uri': 'http://dbpedia.org/resource/Argiope_(spider)',\n",
    "  'description': 'The genus Argiope includes rather large and spectacular spiders that often ...',\n",
    "  'name': 'Argiope',\n",
    "  'synonym': [\"One\", \"Two\"],\n",
    "  'classification': {\n",
    "                    'family': 'Orb-weaver spider',\n",
    "                    'class': 'Arachnid',\n",
    "                    'phylum': 'Arthropod',\n",
    "                    'order': 'Spider',\n",
    "                    'kingdom': 'Animal',\n",
    "                    'genus': None\n",
    "                    }\n",
    "}\n",
    "  * Note that the value associated with the classification key is a dictionary with\n",
    "    taxonomic labels.\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "DATAFILE = 'arachnid.csv'\n",
    "FIELDS ={'rdf-schema#label': 'label',\n",
    "         'URI': 'uri',\n",
    "         'rdf-schema#comment': 'description',\n",
    "         'synonym': 'synonym',\n",
    "         'name': 'name',\n",
    "         'family_label': 'family',\n",
    "         'class_label': 'class',\n",
    "         'phylum_label': 'phylum',\n",
    "         'order_label': 'order',\n",
    "         'kingdom_label': 'kingdom',\n",
    "         'genus_label': 'genus'}\n",
    "\n",
    "def process_file(filename, fields):\n",
    "\n",
    "    \n",
    "    process_fields = fields.keys()\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        count = 0\n",
    "        for line in reader:\n",
    "            for col in line:\n",
    "                if col in FIELDS.keys():\n",
    "                    col = FIELDS.get(col)\n",
    "                    \n",
    "                data.append(line)\n",
    "        print data[0]\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            #FIELDS[] = line.pop[]\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "    #return data\n",
    "process_file(DATAFILE, FIELDS)\n",
    "\n",
    "def parse_array(v):\n",
    "    if (v[0] == \"{\") and (v[-1] == \"}\"):\n",
    "        v = v.lstrip(\"{\")\n",
    "        v = v.rstrip(\"}\")\n",
    "        v_array = v.split(\"|\")\n",
    "        v_array = [i.strip() for i in v_array]\n",
    "        return v_array\n",
    "    return [v]\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     data = process_file(DATAFILE, FIELDS)\n",
    "#     print \"Your first entry:\"\n",
    "#     pprint.pprint(data[0])\n",
    "#     first_entry = {\n",
    "#         \"synonym\": None, \n",
    "#         \"name\": \"Argiope\", \n",
    "#         \"classification\": {\n",
    "#             \"kingdom\": \"Animal\", \n",
    "#             \"family\": \"Orb-weaver spider\", \n",
    "#             \"order\": \"Spider\", \n",
    "#             \"phylum\": \"Arthropod\", \n",
    "#             \"genus\": None, \n",
    "#             \"class\": \"Arachnid\"\n",
    "#         }, \n",
    "#         \"uri\": \"http://dbpedia.org/resource/Argiope_(spider)\", \n",
    "#         \"label\": \"Argiope\", \n",
    "#         \"description\": \"The genus Argiope includes rather large and spectacular spiders that often have a strikingly coloured abdomen. These spiders are distributed throughout the world. Most countries in tropical or temperate climates host one or more species that are similar in appearance. The etymology of the name is from a Greek name meaning silver-faced.\"\n",
    "#     }\n",
    "\n",
    "#     assert len(data) == 76\n",
    "#     assert data[0] == first_entry\n",
    "#     assert data[17][\"name\"] == \"Ogdenia\"\n",
    "#     assert data[48][\"label\"] == \"Hydrachnidiae\"\n",
    "#     assert data[14][\"synonym\"] == [\"Cyrene Peckham & Peckham\"]\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
